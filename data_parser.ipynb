{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "with open(\"stopwords.txt\", \"r\") as f:\n",
    "    stopwords = set(map(lambda w:w.strip(), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(textsample)  \n",
    "words = nltk.word_tokenize(textsample)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_map = {\"J\": \"a\", \"V\": \"v\", \"R\":\"r\"}\n",
    "reg_exp = re.compile(\"[^a-z0-9]+\")\n",
    "\n",
    "def parser(passage):\n",
    "    passage = passage.lower()\n",
    "    sentences = sent_tokenize(passage)\n",
    "    result = []\n",
    "    for s in sentences:\n",
    "        text = reg_exp.sub(\" \", s)\n",
    "        words = [word for word in nltk.word_tokenize(text)]\n",
    "        words = [lemmatizer.lemmatize(words[i], pos=pos_tag_map.get(nltk.pos_tag([words[i]])[0][1][0], \"n\")) for i in range(len(words))]\n",
    "        words = [word for word in words if word not in stopwords]\n",
    "        result += words\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = dict()\n",
    "with open(\"collection.tsv\", encoding='utf-8', mode=\"r\") as f:\n",
    "    r = csv.reader(f, delimiter=\"\\t\")\n",
    "    for i, row in enumerate(r):\n",
    "        pid, passage = row[0], row[1]\n",
    "        passage[pid] = passage #parser(passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808731\n",
      "101093\n",
      "101092\n"
     ]
    }
   ],
   "source": [
    "def read_query(path):\n",
    "    query_dict = dict()\n",
    "    with open(path, encoding='utf-8', mode=\"r\") as f:\n",
    "        r = csv.reader(f, delimiter=\"\\t\")\n",
    "        for i, row in enumerate(r):\n",
    "            qid, query = row[0], row[1]\n",
    "            query_dict[qid] = query #parser(query)\n",
    "    return query_dict\n",
    "\n",
    "train_query = read_query(\"queries.train.tsv\")\n",
    "print(len(train_query))\n",
    "dev_query = read_query(\"queries.dev.tsv\")\n",
    "print(len(dev_query))\n",
    "eval_query = read_query(\"queries.eval.tsv\")\n",
    "print(len(eval_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502939 516472\n",
      "55578 59096\n"
     ]
    }
   ],
   "source": [
    "def read_qrels(path):\n",
    "    query_to_passage_dict = defaultdict(set)\n",
    "    passage_to_query_dict = defaultdict(set)\n",
    "    with open(path, encoding='utf-8', mode=\"r\") as f:\n",
    "        r = csv.reader(f, delimiter=\"\\t\")\n",
    "        for row in r:\n",
    "            qid, pid = row[0], row[2]\n",
    "            query_to_passage_dict[qid].add(pid)\n",
    "            passage_to_query_dict[pid].add(qid)\n",
    "    return query_to_passage_dict, passage_to_query_dict\n",
    "train_qrels_qtp, train_qrels_ptq = read_qrels(\"qrels.train.tsv\")\n",
    "print(len(train_qrels_qtp), len(train_qrels_ptq))\n",
    "dev_qrels_qtp, dev_qrels_ptq = read_qrels(\"qrels.dev.tsv\")\n",
    "print(len(dev_qrels_qtp), len(dev_qrels_ptq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14520 {'605763', '982399', '605764'}\n"
     ]
    }
   ],
   "source": [
    "for pid in train_qrels_ptq:\n",
    "    if len(train_qrels_ptq[pid]) > 2:\n",
    "        print(pid, train_qrels_ptq[pid])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what county is exeter new hampshire im\n",
      "where is exeter nh\n",
      "what county is exeter nh\n"
     ]
    }
   ],
   "source": [
    "print(train_query[\"605763\"])\n",
    "print(train_query[\"982399\"])\n",
    "print(train_query[\"605764\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1997', 'population', '306', 'hampshire', 'new', 'county', '14', 'rockingham', 'office', 'seat', 'move', 's', 'neighbor', 'town', 'census', 'state', 'exeter', '2010', 'brentwood', 'united'}\n",
      "{'new', 'hampshire', 'county', 'im', 'exeter'}\n",
      "{'exeter', 'nh'}\n",
      "{'exeter', 'county', 'nh'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'county': 0.6666666666666666,\n",
       "             'exeter': 1.0,\n",
       "             'hampshire': 0.3333333333333333,\n",
       "             'new': 0.3333333333333333})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query term recall\n",
    "def passage_qtr(pid):\n",
    "    qd = train_qrels_ptq[pid]\n",
    "    passage_terms = set(parser(passage[pid]))\n",
    "    print(passage_terms)\n",
    "    qtr = defaultdict(int)\n",
    "    for qid in qd:\n",
    "        query_terms = set(parser(train_query[qid]))\n",
    "        print(query_terms)\n",
    "        for term in passage_terms:\n",
    "            if term in query_terms:\n",
    "                qtr[term] += 1/len(qd)\n",
    "    return qtr\n",
    "\n",
    "passage_qtr(\"14520\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exeter', 'nh'}\n",
      "{'1997', 'population', '306', 'hampshire', 'new', 'county', '14', 'rockingham', 'office', 'seat', 'move', 's', 'neighbor', 'town', 'census', 'state', 'exeter', '2010', 'brentwood', 'united'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'exeter': 1.0})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_tr(qid):\n",
    "    dq = train_qrels_qtp[qid]\n",
    "    query_terms = set(parser(train_query[qid]))\n",
    "    print(query_terms)\n",
    "    tr = defaultdict(int)\n",
    "    for pid in dq:\n",
    "        passage_terms = set(parser(passage[pid]))\n",
    "        print(passage_terms)\n",
    "        for term in query_terms:\n",
    "            if term in passage_terms:\n",
    "                tr[term] += 1/len(dq)\n",
    "    return tr\n",
    "query_tr(\"982399\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88585 {'17276', '17272', '17277'}\n"
     ]
    }
   ],
   "source": [
    "for qid in train_qrels_qtp:\n",
    "    if len(train_qrels_qtp[qid]) > 2:\n",
    "        print(qid, train_qrels_qtp[qid])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of protein allowed daily for low protein diet\n",
      "Swollen ankles and feet. Swollen ankles and swollen feet are common and are often caused by fluid retention, or oedema. The cause of the swelling can range from an injury to medical conditions. Seek medical advice if you are concerned about swollen feet or ankles.\n",
      "Painless swelling of the feet and ankles is a common problem, especially among older people. Abnormal buildup of fluid in the ankles, feet, and legs can cause swelling. This fluid buildup and swelling is called edema.\n",
      "Injury or surgery involving the leg, ankle, or foot can also cause swelling. Swelling may also occur after pelvic surgery, especially for cancer. Long airplane flights or car rides, as well as standing for long periods of time, often lead to some swelling in the feet and ankles.\n",
      "{'1068701', '587682', '505939', '88585', '587837'}\n"
     ]
    }
   ],
   "source": [
    "print(train_query[\"17276\"])\n",
    "print(passage[\"17276\"])\n",
    "print(passage[\"17272\"])\n",
    "print(passage[\"17277\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ankle', 'cause', 'foot', 'swollen'}\n",
      "{'fluid', 'oedema', 'medical', 'condition', 'concerned', 'advice', 'injury', 'common', 'foot', 'cause', 'seek', 'ankle', 'range', 'retention', 'swollen', 'swell'}\n",
      "{'fluid', 'leg', 'buildup', 'painless', 'especially', 'edema', 'common', 'foot', 'abnormal', 'cause', 'problem', 'old', 'ankle', 'people', 'call', 'swell'}\n",
      "{'involve', 'swell', 'flight', 'leg', 'especially', 'cause', 'foot', 'occur', 'ride', 'ankle', 'pelvic', 'stand', 'injury', 'period', 'lead', 'cancer', 'airplane', 'car', 'long', 'time', 'surgery'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'ankle': 1.0,\n",
       "             'cause': 1.0,\n",
       "             'foot': 1.0,\n",
       "             'swollen': 0.3333333333333333})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tr(\"88585\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
